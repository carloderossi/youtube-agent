llm:
  provider: "ollama"        # "ollama" or "openai"
  model: "qwen3:1.7b"     # Model name for the selected provider
  temperature: 0         # Sampling temperature

openai:
  model: "gpt-4o-mini"  # OpenAI model name

youtube:
  add_video_info:   

deep_search:
  enabled: false
  max_results: 20
  highlight_youtube: true